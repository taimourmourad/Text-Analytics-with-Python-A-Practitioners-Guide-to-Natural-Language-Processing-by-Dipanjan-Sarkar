{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nips12raw_str602', <http.client.HTTPMessage at 0x7fe75b8f9100>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'\n",
    "filename = 'nips12raw_str602'\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf nips12raw_str602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orig', 'nips06', 'nips08', 'nips00', 'nips04', 'idx', 'nips02', 'README_yann', 'nips10', 'nips11', 'nips01', 'nips03', 'nips09', 'nips12', 'nips07', 'MATLAB_NOTES', 'nips05', 'RAW_DATA_NOTES']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 \n",
      "INTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET \n",
      "CONNECTIONS ON SIMD ARCHITECTURES \n",
      "Sherryl Tomboulian \n",
      "Institute for Computer Applications in Science and Engineering \n",
      "NASA Langley Research Center, Hampton VA 23665 \n",
      "ABSTRACT \n",
      "Neural networks have attracted much interest recently, and using parallel \n",
      "architectures to simulate neural networks is a natural and necessary applica- \n",
      "tion. The SIMD model of parallel computation is chosen, because systems of \n",
      "this type can be built with large numbers of processing elements. However, \n",
      "such systems are not naturally suited to generalized communication. A method \n",
      "is proposed that allows an implementation of neural network connections on \n",
      "massively parallel SIMD architectures. The key to this system is an algorithm \n",
      "that allows the formation of arbitrary connections between the 'neurons '. A \n",
      "feature is the ability to add new connections quickly. It also has error recov- \n",
      "ery ability and is robust over a variety of network topologies. Si\n"
     ]
    }
   ],
   "source": [
    "folders = ['nips{0:02}'.format(i) for i in range(0, 13)]\n",
    "# Read all texts into a list\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:#seperate 'em with /\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)        \n",
    "\n",
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]# word tokenization\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['introduction', 'system', 'implementing', 'neural', 'net', 'connection', 'simd', 'architecture', 'sherryl', 'tomboulian', 'institute', 'computer', 'application', 'science', 'engineering', 'nasa', 'langley', 'research', 'center', 'hampton', 'va', 'abstract', 'neural', 'network', 'attracted', 'much', 'interest', 'recently', 'using', 'parallel', 'architecture', 'simulate', 'neural', 'network', 'natural', 'necessary', 'applica', 'tion', 'simd', 'model', 'parallel', 'computation', 'chosen', 'system', 'type', 'built', 'large', 'number', 'processing', 'element']\n"
     ]
    }
   ],
   "source": [
    "# Viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1740, 14408)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv=CountVectorizer(min_df=20, max_df=0.6,ngram_range=(1, 2),token_pattern=None,tokenizer=lambda doc:doc,preprocessor=lambda doc:doc)\n",
    "cv_features = cv.fit_transform(norm_papers)\n",
    "cv_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 14408\n"
     ]
    }
   ],
   "source": [
    "# validating vocaublary size\n",
    "vocabulary = np.array(cv.get_feature_names())\n",
    "print('Total Vocabulary Size:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF:\n",
    "    <br>\n",
    "    1. which is another matrix decomposition technique similar to SVD but operates on non-negative matrices and works well for multlivairate data\n",
    "    2. the objective of NMF is to find 2 non-negative matrix factors, W and H, such that when they are multiplied,they can approximaltey reconstruct V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can build an NMF based topic model using the following snippet on out toy corpus,whihc gives us the feature names and their weights just like in LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tevo/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/home/tevo/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 500 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "TOTAL_TOPICS = 20\n",
    "nmf_model = NMF(n_components=TOTAL_TOPICS,solver='cd', max_iter=500,random_state=42, alpha=0.1,l1_ratio=0.85)\n",
    "document_topics = nmf_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our model trained, we can look at the generated topics using the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated topics from our NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-b310e4d4bbe1>:6: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, generalization, output unit, neural net, training set, test, learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>cell, firing, head, direction, response, rat, layer, cortex, activity, spatial, synaptic, inhibitory, synapsis, simulation, cue, property, complex, active, lot, cortical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>signal, noise, source, filter, component, frequency, channel, speech, matrix, independent, separation, sound, ica, phase, eeg, blind, auditory, dynamic, delay, fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>control, controller, trajectory, motor, dynamic, movement, task, forward, feedback, arm, inverse, position, robot, architecture, hand, force, adaptive, change, command, plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>circuit, chip, current, analog, voltage, vlsi, gate, threshold, transistor, pulse, design, implementation, synapse, bit, digital, device, analog vlsi, pp, cmos, element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, signal, change, temporal, probability, timing, correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>rule, learning rule, knowledge, category, condition, domain, symbolic, change, fuzzy, step, extraction, table, interval, eq, expert, trained, learn, activation, learned, language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>node, tree, decision, level, graph, structure, layer, decision tree, probability, leaf, bound, variable, path, activation, parent, field, child, split, routing, architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>feature, map, task, search, experiment, classification, part, representation, target, orientation, feature map, attention, location, dimensional, feature vector, feature space, cluster, kernel, test, block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>classifier, class, classification, decision, rbf, rate, test, error rate, center, nearest, probability, neighbor, region, nearest neighbor, layer, boundary, sample, training set, trained, gaussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>motion, field, visual, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, location, center, target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>object, view, recognition, representation, layer, visual, 3d, 2d, part, human, object recognition, position, transformation, scheme, image, aspect, frame, shape, viewpoint, rotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>region, ii, chain, mouse, ig, human, ii ii, protein, domain, class, receptor, beta, cell, heavy, iii, alpha, sequence, border, texture, search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>memory, representation, structure, capacity, sequence, associative, role, distributed, matrix, associative memory, activity, bit, stored, product, binding, connection, code, local, activation, attractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                     Terms per Topic\n",
       "Topic1   bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum                                            \n",
       "Topic2   neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation                                   \n",
       "Topic3   state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, decision                 \n",
       "Topic4   image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database                                               \n",
       "Topic5   hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, generalization, output unit, neural net, training set, test, learn\n",
       "Topic6   cell, firing, head, direction, response, rat, layer, cortex, activity, spatial, synaptic, inhibitory, synapsis, simulation, cue, property, complex, active, lot, cortical                                                  \n",
       "Topic7   word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state                               \n",
       "Topic8   signal, noise, source, filter, component, frequency, channel, speech, matrix, independent, separation, sound, ica, phase, eeg, blind, auditory, dynamic, delay, fig                                                        \n",
       "Topic9   control, controller, trajectory, motor, dynamic, movement, task, forward, feedback, arm, inverse, position, robot, architecture, hand, force, adaptive, change, command, plant                                             \n",
       "Topic10  circuit, chip, current, analog, voltage, vlsi, gate, threshold, transistor, pulse, design, implementation, synapse, bit, digital, device, analog vlsi, pp, cmos, element                                                   \n",
       "Topic11  spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, signal, change, temporal, probability, timing, correlation                                 \n",
       "Topic12  rule, learning rule, knowledge, category, condition, domain, symbolic, change, fuzzy, step, extraction, table, interval, eq, expert, trained, learn, activation, learned, language                                         \n",
       "Topic13  node, tree, decision, level, graph, structure, layer, decision tree, probability, leaf, bound, variable, path, activation, parent, field, child, split, routing, architecture                                              \n",
       "Topic14  feature, map, task, search, experiment, classification, part, representation, target, orientation, feature map, attention, location, dimensional, feature vector, feature space, cluster, kernel, test, block              \n",
       "Topic15  classifier, class, classification, decision, rbf, rate, test, error rate, center, nearest, probability, neighbor, region, nearest neighbor, layer, boundary, sample, training set, trained, gaussian                       \n",
       "Topic16  distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum                     \n",
       "Topic17  motion, field, visual, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, location, center, target                                 \n",
       "Topic18  object, view, recognition, representation, layer, visual, 3d, 2d, part, human, object recognition, position, transformation, scheme, image, aspect, frame, shape, viewpoint, rotation                                      \n",
       "Topic19  region, ii, chain, mouse, ig, human, ii ii, protein, domain, class, receptor, beta, cell, heavy, iii, alpha, sequence, border, texture, search                                                                             \n",
       "Topic20  memory, representation, structure, capacity, sequence, associative, role, distributed, matrix, associative memory, activity, bit, stored, product, binding, connection, code, local, activation, attractor                 "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_terms = nmf_model.components_\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics, columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the topics depicted in the Figure:\n",
    "    <br>\n",
    "    1. there are no major repitions of topics and each topic talks about a clear and distinct theme\n",
    "    2. the results from the NMF topic model are definitely better than what we obtained from LDA in Scikit-Learn\n",
    "    3. we can determine the dominance of topics in each research paper but, in case of NMF these are determined by absolute scores and not percenteges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095</td>\n",
       "      <td>1.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320</td>\n",
       "      <td>1.468</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.403</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.261</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T1    T2    T3    T4    T5    T6    T7    T8    T9   T10   T11   T12  \\\n",
       "0 0.095 1.598 0.000 0.010 0.372 0.000 0.000 0.000 0.156 0.469 0.000 0.188   \n",
       "1 0.320 1.468 0.554 0.000 0.000 0.000 0.110 0.281 0.000 0.208 0.000 0.000   \n",
       "2 0.852 0.148 0.694 0.038 0.000 0.017 0.000 0.234 0.244 0.332 0.000 0.123   \n",
       "3 0.115 0.139 0.000 0.000 0.607 0.013 0.013 0.018 0.033 0.000 0.000 0.075   \n",
       "4 0.341 0.003 0.000 0.001 0.365 0.000 0.000 0.061 0.053 0.000 0.000 0.597   \n",
       "5 0.265 0.000 0.147 0.684 0.000 0.000 0.000 0.127 0.052 1.039 0.000 0.083   \n",
       "6 0.000 0.563 0.674 0.000 0.279 0.000 0.000 0.046 0.000 0.024 0.000 0.000   \n",
       "7 0.266 0.000 0.000 0.039 0.551 0.000 0.043 0.466 0.000 0.000 0.018 0.063   \n",
       "8 0.000 0.267 0.000 0.010 0.040 0.073 0.365 0.914 0.311 0.402 0.137 0.051   \n",
       "9 0.403 0.004 0.041 1.261 0.132 0.021 0.000 0.364 0.071 0.062 0.000 0.043   \n",
       "\n",
       "    T13   T14   T15   T16   T17   T18   T19   T20  \n",
       "0 0.623 0.207 0.064 0.000 0.212 0.000 0.000 1.140  \n",
       "1 0.598 0.000 0.109 0.153 0.089 0.000 0.059 0.860  \n",
       "2 0.000 0.145 0.000 0.127 0.374 0.032 0.026 0.437  \n",
       "3 0.808 0.013 0.059 0.274 0.009 0.028 0.000 0.000  \n",
       "4 0.000 0.037 0.039 0.000 0.068 0.000 0.297 0.000  \n",
       "5 0.399 0.032 0.000 0.089 0.793 0.034 0.000 0.000  \n",
       "6 0.000 0.000 0.095 0.000 0.000 0.000 0.000 2.707  \n",
       "7 0.000 0.466 0.070 0.130 0.000 0.007 0.202 0.000  \n",
       "8 0.060 0.065 0.013 0.000 0.030 0.029 0.188 0.210  \n",
       "9 0.000 0.030 0.000 0.054 0.345 0.131 0.005 0.008  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "dt_df = pd.DataFrame(document_topics, columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "dt_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leveraging the document_topic matrix, we can determine the most relevant paper for each topic based on the topic dominance scores by using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Max Score</th>\n",
       "      <th>Paper Num</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Paper Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>T1</td>\n",
       "      <td>1.66103</td>\n",
       "      <td>1128</td>\n",
       "      <td>bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum</td>\n",
       "      <td>A Bound on the Error of Cross Validation Using \\nthe Approximation and Estimation Rates, with \\nConsequences for the Training-Test Split \\nMichael Kearns \\nAT&amp;T Research \\nABSTRACT\\n1 INTRODUCTION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>T2</td>\n",
       "      <td>3.56069</td>\n",
       "      <td>1681</td>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation</td>\n",
       "      <td>Predictive Sequence Learning in Recurrent \\nNeocortical Circuits* \\nR. P. N. Rao \\nComputational Neurobiology Lab and \\nSloan Center for Theoretical Neurobiology \\nThe Salk Institute, La Jolla, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>T3</td>\n",
       "      <td>5.85746</td>\n",
       "      <td>1286</td>\n",
       "      <td>state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, de...</td>\n",
       "      <td>Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>T4</td>\n",
       "      <td>3.94621</td>\n",
       "      <td>1645</td>\n",
       "      <td>image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database</td>\n",
       "      <td>Image representations for facial expression \\ncoding \\nMarian Stewart Bartlett* \\nU.C. San Diego \\nmarnisalk. edu \\nJavier R. Movellan \\nU.C. San Diego \\nmovellancogsc. ucsd. edu \\nPaul Ekman \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>T5</td>\n",
       "      <td>3.01659</td>\n",
       "      <td>86</td>\n",
       "      <td>hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, generalization, output unit, neural net, tr...</td>\n",
       "      <td>5O5 \\nCONNECTING TO THE PAST \\nBruce A. MacDonald, Assistant Professor \\nKnowledge Sciences Laboratory, Computer Science Department \\nThe University of Calgary, 2500 University Drive NW \\nCalgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>T6</td>\n",
       "      <td>7.56565</td>\n",
       "      <td>66</td>\n",
       "      <td>cell, firing, head, direction, response, rat, layer, cortex, activity, spatial, synaptic, inhibitory, synapsis, simulation, cue, property, complex, active, lot, cortical</td>\n",
       "      <td>317 \\nPARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  \\nRichard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch \\nCenter for the Neurobiology of Learning and Memory \\nUniversity of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>T7</td>\n",
       "      <td>4.93454</td>\n",
       "      <td>1374</td>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "      <td>Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>T8</td>\n",
       "      <td>3.60644</td>\n",
       "      <td>275</td>\n",
       "      <td>signal, noise, source, filter, component, frequency, channel, speech, matrix, independent, separation, sound, ica, phase, eeg, blind, auditory, dynamic, delay, fig</td>\n",
       "      <td>232 Sejnowski, Yuhas, Goldstein and Jenkins \\nCombining Visual and \\nwith a Neural Network \\nAcoustic Speech Signals \\nImproves Intelligibility \\nT.J. Sejnowski \\nThe Salk Institute \\nand \\nDepart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>T9</td>\n",
       "      <td>4.83627</td>\n",
       "      <td>886</td>\n",
       "      <td>control, controller, trajectory, motor, dynamic, movement, task, forward, feedback, arm, inverse, position, robot, architecture, hand, force, adaptive, change, command, plant</td>\n",
       "      <td>An Integrated Architecture of Adaptive Neural Network \\nControl for Dynamic Systems \\nLiu Ke '2 Robert L. Tokaf Brian D.McVey z \\nCenter for Nonlinear Studies, 2Applied Theoretical Physics Divis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>T10</td>\n",
       "      <td>2.96307</td>\n",
       "      <td>1689</td>\n",
       "      <td>circuit, chip, current, analog, voltage, vlsi, gate, threshold, transistor, pulse, design, implementation, synapse, bit, digital, device, analog vlsi, pp, cmos, element</td>\n",
       "      <td>Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>T11</td>\n",
       "      <td>6.20635</td>\n",
       "      <td>1002</td>\n",
       "      <td>spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, signal, change, temporal, probability, timing, correlation</td>\n",
       "      <td>Information through a Spiking Neuron \\nCharles F. Stevens and Anthony Zador \\nSalk Institute MNL/S \\nLa Jolla, CA 92037 \\nzador@salk.edu \\nAbstract \\nWhile it is generally agreed that neurons tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>T12</td>\n",
       "      <td>6.08571</td>\n",
       "      <td>980</td>\n",
       "      <td>rule, learning rule, knowledge, category, condition, domain, symbolic, change, fuzzy, step, extraction, table, interval, eq, expert, trained, learn, activation, learned, language</td>\n",
       "      <td>Extracting Rules from Artificial Neural Networks \\nwith Distributed Representations \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nR6merstr. 164, D-53117 Bonn, Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>T13</td>\n",
       "      <td>3.60985</td>\n",
       "      <td>1618</td>\n",
       "      <td>node, tree, decision, level, graph, structure, layer, decision tree, probability, leaf, bound, variable, path, activation, parent, field, child, split, routing, architecture</td>\n",
       "      <td>Boosting with Multi-Way Branching in \\nDecision Trees \\nYishay Mansour \\nDavid McAllester \\nAT&amp;T Labs-Research \\n180 Park Ave \\nFlorham Park NJ 07932 \\n{mansour, dmac}@research.att.com \\nAbstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>T14</td>\n",
       "      <td>3.95184</td>\n",
       "      <td>213</td>\n",
       "      <td>feature, map, task, search, experiment, classification, part, representation, target, orientation, feature map, attention, location, dimensional, feature vector, feature space, cluster, kernel, te...</td>\n",
       "      <td>266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>T15</td>\n",
       "      <td>5.00628</td>\n",
       "      <td>198</td>\n",
       "      <td>classifier, class, classification, decision, rbf, rate, test, error rate, center, nearest, probability, neighbor, region, nearest neighbor, layer, boundary, sample, training set, trained, gaussian</td>\n",
       "      <td>168 Lee and Lippmann \\nPractical Characteristics of Neural Network \\nand Conventional Pattern Classifiers on \\nArtificial and Speech Problems* \\nYuchun Lee \\nDigital Equipment Corp. \\n40 Old Bolto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>T16</td>\n",
       "      <td>2.73475</td>\n",
       "      <td>1034</td>\n",
       "      <td>distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum</td>\n",
       "      <td>Discovering Structure in Continuous \\nVariables Using Bayesian Networks \\nReimar Hofmann and Volker Tresp* \\nSiemens AG, Central Research \\nOtto-Hahn-Ring 6 \\n81730 Mfinchen, Germany \\nAbstract \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>T17</td>\n",
       "      <td>3.39368</td>\n",
       "      <td>689</td>\n",
       "      <td>motion, field, visual, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, location, center, target</td>\n",
       "      <td>Filter Selection Model for Generating \\nVisual Motion Signals \\nSteven J. Nowlan* \\nCNL, The Salk Institute \\nP.O. Box 85800, San Diego, CA \\n92186-5800 \\nTerrence J. Sejnowski \\nCNL, The Salk Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>T18</td>\n",
       "      <td>5.64273</td>\n",
       "      <td>484</td>\n",
       "      <td>object, view, recognition, representation, layer, visual, 3d, 2d, part, human, object recognition, position, transformation, scheme, image, aspect, frame, shape, viewpoint, rotation</td>\n",
       "      <td>Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>T19</td>\n",
       "      <td>14.43654</td>\n",
       "      <td>266</td>\n",
       "      <td>region, ii, chain, mouse, ig, human, ii ii, protein, domain, class, receptor, beta, cell, heavy, iii, alpha, sequence, border, texture, search</td>\n",
       "      <td>A Neural Network to Detect \\nHomologies in Proteins \\nYoshua Bengio \\nSchool of Computer Science \\nMcGill University \\nMontreal, Canada H3A 2A7 \\nSamy Bengio \\nDepartement d'Informatique \\nUnivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>T20</td>\n",
       "      <td>5.89046</td>\n",
       "      <td>60</td>\n",
       "      <td>memory, representation, structure, capacity, sequence, associative, role, distributed, matrix, associative memory, activity, bit, stored, product, binding, connection, code, local, activation, att...</td>\n",
       "      <td>73O \\nAnalysis of distributed representation of \\nconstituent structure in connectionist systems \\nPaul Smolensky \\nDepartment of Computer Science, University of Colorado, Boulder, CO 80309-0430 \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topic  Max Score  Paper Num  \\\n",
       "Topic1              T1    1.66103       1128   \n",
       "Topic2              T2    3.56069       1681   \n",
       "Topic3              T3    5.85746       1286   \n",
       "Topic4              T4    3.94621       1645   \n",
       "Topic5              T5    3.01659         86   \n",
       "Topic6              T6    7.56565         66   \n",
       "Topic7              T7    4.93454       1374   \n",
       "Topic8              T8    3.60644        275   \n",
       "Topic9              T9    4.83627        886   \n",
       "Topic10            T10    2.96307       1689   \n",
       "Topic11            T11    6.20635       1002   \n",
       "Topic12            T12    6.08571        980   \n",
       "Topic13            T13    3.60985       1618   \n",
       "Topic14            T14    3.95184        213   \n",
       "Topic15            T15    5.00628        198   \n",
       "Topic16            T16    2.73475       1034   \n",
       "Topic17            T17    3.39368        689   \n",
       "Topic18            T18    5.64273        484   \n",
       "Topic19            T19   14.43654        266   \n",
       "Topic20            T20    5.89046         60   \n",
       "\n",
       "                                                                                                                                                                                                           Topic  \\\n",
       "Topic1                           bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum   \n",
       "Topic2                  neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation   \n",
       "Topic3   state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, de...   \n",
       "Topic4                              image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database   \n",
       "Topic5   hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, generalization, output unit, neural net, tr...   \n",
       "Topic6                                 cell, firing, head, direction, response, rat, layer, cortex, activity, spatial, synaptic, inhibitory, synapsis, simulation, cue, property, complex, active, lot, cortical   \n",
       "Topic7              word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state   \n",
       "Topic8                                       signal, noise, source, filter, component, frequency, channel, speech, matrix, independent, separation, sound, ica, phase, eeg, blind, auditory, dynamic, delay, fig   \n",
       "Topic9                            control, controller, trajectory, motor, dynamic, movement, task, forward, feedback, arm, inverse, position, robot, architecture, hand, force, adaptive, change, command, plant   \n",
       "Topic10                                 circuit, chip, current, analog, voltage, vlsi, gate, threshold, transistor, pulse, design, implementation, synapse, bit, digital, device, analog vlsi, pp, cmos, element   \n",
       "Topic11               spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, signal, change, temporal, probability, timing, correlation   \n",
       "Topic12                       rule, learning rule, knowledge, category, condition, domain, symbolic, change, fuzzy, step, extraction, table, interval, eq, expert, trained, learn, activation, learned, language   \n",
       "Topic13                            node, tree, decision, level, graph, structure, layer, decision tree, probability, leaf, bound, variable, path, activation, parent, field, child, split, routing, architecture   \n",
       "Topic14  feature, map, task, search, experiment, classification, part, representation, target, orientation, feature map, attention, location, dimensional, feature vector, feature space, cluster, kernel, te...   \n",
       "Topic15     classifier, class, classification, decision, rbf, rate, test, error rate, center, nearest, probability, neighbor, region, nearest neighbor, layer, boundary, sample, training set, trained, gaussian   \n",
       "Topic16   distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum   \n",
       "Topic17               motion, field, visual, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, location, center, target   \n",
       "Topic18                    object, view, recognition, representation, layer, visual, 3d, 2d, part, human, object recognition, position, transformation, scheme, image, aspect, frame, shape, viewpoint, rotation   \n",
       "Topic19                                                           region, ii, chain, mouse, ig, human, ii ii, protein, domain, class, receptor, beta, cell, heavy, iii, alpha, sequence, border, texture, search   \n",
       "Topic20  memory, representation, structure, capacity, sequence, associative, role, distributed, matrix, associative memory, activity, bit, stored, product, binding, connection, code, local, activation, att...   \n",
       "\n",
       "                                                                                                                                                                                                      Paper Name  \n",
       "Topic1   A Bound on the Error of Cross Validation Using \\nthe Approximation and Estimation Rates, with \\nConsequences for the Training-Test Split \\nMichael Kearns \\nAT&T Research \\nABSTRACT\\n1 INTRODUCTION...  \n",
       "Topic2   Predictive Sequence Learning in Recurrent \\nNeocortical Circuits* \\nR. P. N. Rao \\nComputational Neurobiology Lab and \\nSloan Center for Theoretical Neurobiology \\nThe Salk Institute, La Jolla, CA...  \n",
       "Topic3   Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...  \n",
       "Topic4   Image representations for facial expression \\ncoding \\nMarian Stewart Bartlett* \\nU.C. San Diego \\nmarnisalk. edu \\nJavier R. Movellan \\nU.C. San Diego \\nmovellancogsc. ucsd. edu \\nPaul Ekman \\n...  \n",
       "Topic5   5O5 \\nCONNECTING TO THE PAST \\nBruce A. MacDonald, Assistant Professor \\nKnowledge Sciences Laboratory, Computer Science Department \\nThe University of Calgary, 2500 University Drive NW \\nCalgary,...  \n",
       "Topic6   317 \\nPARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  \\nRichard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch \\nCenter for the Neurobiology of Learning and Memory \\nUniversity of...  \n",
       "Topic7   Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...  \n",
       "Topic8   232 Sejnowski, Yuhas, Goldstein and Jenkins \\nCombining Visual and \\nwith a Neural Network \\nAcoustic Speech Signals \\nImproves Intelligibility \\nT.J. Sejnowski \\nThe Salk Institute \\nand \\nDepart...  \n",
       "Topic9   An Integrated Architecture of Adaptive Neural Network \\nControl for Dynamic Systems \\nLiu Ke '2 Robert L. Tokaf Brian D.McVey z \\nCenter for Nonlinear Studies, 2Applied Theoretical Physics Divis...  \n",
       "Topic10  Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...  \n",
       "Topic11  Information through a Spiking Neuron \\nCharles F. Stevens and Anthony Zador \\nSalk Institute MNL/S \\nLa Jolla, CA 92037 \\nzador@salk.edu \\nAbstract \\nWhile it is generally agreed that neurons tran...  \n",
       "Topic12  Extracting Rules from Artificial Neural Networks \\nwith Distributed Representations \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nR6merstr. 164, D-53117 Bonn, Germa...  \n",
       "Topic13  Boosting with Multi-Way Branching in \\nDecision Trees \\nYishay Mansour \\nDavid McAllester \\nAT&T Labs-Research \\n180 Park Ave \\nFlorham Park NJ 07932 \\n{mansour, dmac}@research.att.com \\nAbstract ...  \n",
       "Topic14  266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...  \n",
       "Topic15  168 Lee and Lippmann \\nPractical Characteristics of Neural Network \\nand Conventional Pattern Classifiers on \\nArtificial and Speech Problems* \\nYuchun Lee \\nDigital Equipment Corp. \\n40 Old Bolto...  \n",
       "Topic16  Discovering Structure in Continuous \\nVariables Using Bayesian Networks \\nReimar Hofmann and Volker Tresp* \\nSiemens AG, Central Research \\nOtto-Hahn-Ring 6 \\n81730 Mfinchen, Germany \\nAbstract \\n...  \n",
       "Topic17  Filter Selection Model for Generating \\nVisual Motion Signals \\nSteven J. Nowlan* \\nCNL, The Salk Institute \\nP.O. Box 85800, San Diego, CA \\n92186-5800 \\nTerrence J. Sejnowski \\nCNL, The Salk Ins...  \n",
       "Topic18  Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...  \n",
       "Topic19  A Neural Network to Detect \\nHomologies in Proteins \\nYoshua Bengio \\nSchool of Computer Science \\nMcGill University \\nMontreal, Canada H3A 2A7 \\nSamy Bengio \\nDepartement d'Informatique \\nUnivers...  \n",
       "Topic20  73O \\nAnalysis of distributed representation of \\nconstituent structure in connectionist systems \\nPaul Smolensky \\nDepartment of Computer Science, University of Colorado, Boulder, CO 80309-0430 \\...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_score_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_score_topics.index\n",
    "term_score = max_score_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_score_topics.loc[t]].index[0] for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Max Score': term_score,\n",
    "                          'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'], \n",
    "                          'Paper Name': documents})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs depicted in Figure 6-18 clearly show that the NMF model is much better than the LDA model:\n",
    "    <br>\n",
    "    1. with each topic being strongly correlated as the central theme of the research paper where it has maximum dominance\n",
    "    2. What we have observed is that non-negative matrix factorization works the best even with small corpora, with few documents compared to the other methods\n",
    "    3. . But again, this depends on the type of data you are dealing with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Topics for New Research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total New Papers: 4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('./test_data/nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "              \n",
    "print('Total New Papers:', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 14408)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_new_papers = normalize_corpus(new_papers)\n",
    "cv_new_features = cv.transform(norm_new_papers)\n",
    "cv_new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 2.149), (1, 1.343)],\n",
       " [(0, 1.127), (15, 0.836)],\n",
       " [(3, 3.066), (6, 2.212)],\n",
       " [(2, 4.14), (0, 0.87)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predictions = nmf_model.transform(cv_new_features)\n",
    "best_topics = [[(topic, round(sc, 3)) \n",
    "                    for topic, sc in sorted(enumerate(topic_predictions[i]), \n",
    "                                            key=lambda row: -row[1])[:2]] \n",
    "                        for i in range(len(topic_predictions))]\n",
    "best_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topics</th>\n",
       "      <th>Topic Score</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper Desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>214.90000</td>\n",
       "      <td>image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>134.30000</td>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>112.70000</td>\n",
       "      <td>bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>83.60000</td>\n",
       "      <td>distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>306.60000</td>\n",
       "      <td>image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>221.20000</td>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>414.00000</td>\n",
       "      <td>state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, de...</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topics  Topic Score  \\\n",
       "Papers                                 \n",
       "1                     4    214.90000   \n",
       "1                     2    134.30000   \n",
       "2                     1    112.70000   \n",
       "2                    16     83.60000   \n",
       "3                     4    306.60000   \n",
       "3                     7    221.20000   \n",
       "4                     3    414.00000   \n",
       "4                     1     87.00000   \n",
       "\n",
       "                                                                                                                                                                                                     Topic Desc  \\\n",
       "Papers                                                                                                                                                                                                            \n",
       "1                                  image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database   \n",
       "1                      neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, equation, state, et, et al, fig, activation   \n",
       "2                               bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum   \n",
       "2        distribution, probability, gaussian, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, matrix, conditional, maximum   \n",
       "3                                  image, face, pixel, recognition, local, distance, scale, digit, texture, filter, scene, vision, facial, pca, edge, transformation, representation, visual, surface, database   \n",
       "3                  word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state   \n",
       "4       state, action, policy, step, optimal, reinforcement, transition, reinforcement learning, probability, reward, dynamic, value function, markov, machine, task, agent, finite, iteration, sequence, de...   \n",
       "4                               bound, generalization, size, let, optimal, solution, equation, theorem, approximation, gradient, class, xi, loss, rate, matrix, convergence, theory, dimension, sample, minimum   \n",
       "\n",
       "                                                                                                                                                                                                     Paper Desc  \n",
       "Papers                                                                                                                                                                                                           \n",
       "1       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
       "1       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
       "2       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
       "2       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
       "3       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  \n",
       "3       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  \n",
       "4       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  \n",
       "4       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, sc in item] for item in best_topics]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Topic Score'] = [topic_sc for topic_list in \n",
    "                                        [[round(sc*100, 2) \n",
    "                                              for topic_num, sc in item] \n",
    "                                                 for item in best_topics] \n",
    "                                    for topic_sc in topic_list]\n",
    "\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting Model and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('nmf_model.pkl', 'wb') as f:\n",
    "    dill.dump(nmf_model, f)\n",
    "with open('cv_features.pkl', 'wb') as f:\n",
    "    dill.dump(cv_features, f)\n",
    "with open('cv.pkl', 'wb') as f:\n",
    "    dill.dump(cv, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
